{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "52aee6b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.9.13 (main, Oct 13 2022, 16:12:30) \n",
      "[Clang 12.0.0 ]\n",
      "['/Users/eduardo/Documents/CUNEF_ASIGNATURAS/MLEAR/practica0/notebook', '/Users/eduardo/opt/anaconda3/envs/practica0/lib/python39.zip', '/Users/eduardo/opt/anaconda3/envs/practica0/lib/python3.9', '/Users/eduardo/opt/anaconda3/envs/practica0/lib/python3.9/lib-dynload', '', '/Users/eduardo/opt/anaconda3/envs/practica0/lib/python3.9/site-packages']\n",
      "---\n",
      "/Users/eduardo/opt/anaconda3/envs/practica0/bin/Python\n"
     ]
    }
   ],
   "source": [
    "# Check environment\n",
    "import sys\n",
    "\n",
    "print(sys.version)\n",
    "print(sys.path)\n",
    "print(\"---\")\n",
    "print(sys.executable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2f98fd5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# primero todas las librerías por bloques\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "653886ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# opciones de visualización\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58229002",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('../data/raw/Loan_test_set.csv', skiprows=[0])\n",
    "df2 = pd.read_csv('../data/raw/Loan_training_set_1_4.csv', skiprows=[0])\n",
    "df3 = pd.read_csv('../data/raw/Loan_training_set_2_4.csv', skiprows=[0])\n",
    "df4 = pd.read_csv('../data/raw/Loan_training_set_3_4.csv', skiprows=[0])\n",
    "df5 = pd.read_csv('../data/raw/Loan_training_set_4_4.csv', skiprows=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d904a660",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = np.dstack((list(df1.columns), list(df2.columns), list(df3.columns), list(df4.columns), list(df5.columns))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcb33ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "coldf = pd.DataFrame(columns[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ea3a413",
   "metadata": {},
   "outputs": [],
   "source": [
    "coldf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9e4c864",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df1, df2, df3, df4, df5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a38eb1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bf67984",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list(df.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89d5da47",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51a2563a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes.sort_values().to_frame('feature_type').groupby(by = 'feature_type').size().to_frame('count').reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adac566a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analizar una variable concreta\n",
    "df.loan_status.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74a7e807",
   "metadata": {},
   "outputs": [],
   "source": [
    "# analizar nulos\n",
    "df_dtypes = pd.merge(df.isnull().sum(axis = 0).sort_values().to_frame('missing_value').reset_index(),\n",
    "         df.dtypes.to_frame('feature_type').reset_index(),\n",
    "         on = 'index',\n",
    "         how = 'inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61ec86d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dtypes.sort_values(['missing_value', 'feature_type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "615809c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check columns have more than  400000  missing values ( ≈90% )\n",
    "missing_df = df.isnull().sum(axis = 0).sort_values().to_frame('missing_value').reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae20274e",
   "metadata": {},
   "outputs": [],
   "source": [
    "miss_4000 = list(missing_df[missing_df.missing_value >= 400000]['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ddef6ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(miss_4000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8495744",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sorted(miss_4000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64f46d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def duplicate_columns(frame):\n",
    "    groups = frame.columns.to_series().groupby(frame.dtypes).groups\n",
    "    dups = []\n",
    "\n",
    "    for t, v in groups.items():\n",
    "\n",
    "        cs = frame[v].columns\n",
    "        vs = frame[v]\n",
    "        lcs = len(cs)\n",
    "\n",
    "        for i in range(lcs):\n",
    "            ia = vs.iloc[:,i].values\n",
    "            for j in range(i+1, lcs):\n",
    "                ja = vs.iloc[:,j].values\n",
    "                if np.array_equal(ia, ja):\n",
    "                    dups.append(cs[i])\n",
    "                    break\n",
    "    return dups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02a6abf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicate_cols = duplicate_columns(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76e90214",
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicate_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49118cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c06806e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_feature(col_name, isContinuous):\n",
    "    \"\"\"\n",
    "    Visualize a variable with and without faceting on the loan status.\n",
    "    - col_name is the variable name in the dataframe\n",
    "    - full_name is the full variable name\n",
    "    - continuous is True if the variable is continuous, False otherwise\n",
    "    \"\"\"\n",
    "    f, (ax1, ax2) = plt.subplots(nrows=1, ncols=2, figsize=(12,3), dpi=90)\n",
    "    \n",
    "    # Plot without loan status\n",
    "    if isContinuous:\n",
    "        sns.distplot(df.loc[df[col_name].notnull(), col_name], kde=False, ax=ax1)\n",
    "    else:\n",
    "        sns.countplot(df[col_name], order=sorted(df[col_name].unique()), color='#5975A4', saturation=1, ax=ax1)\n",
    "    ax1.set_xlabel(col_name)\n",
    "    ax1.set_ylabel('Count')\n",
    "    ax1.set_title(col_name)\n",
    "    plt.xticks(rotation = 90)\n",
    "\n",
    "    # Plot with loan status\n",
    "    if isContinuous:\n",
    "        sns.boxplot(x=col_name, y='loan_status', data=df, ax=ax2)\n",
    "        ax2.set_ylabel('')\n",
    "        ax2.set_title(col_name + ' by Loan Status')\n",
    "    else:\n",
    "        data = df.groupby(col_name)['loan_status'].value_counts(normalize=True).to_frame('proportion').reset_index()        \n",
    "        sns.barplot(x = col_name, y = 'proportion', hue= \"loan_status\", data = data, saturation=1, ax=ax2)\n",
    "        ax2.set_ylabel('Loan fraction')\n",
    "        ax2.set_title('Loan status')\n",
    "        plt.xticks(rotation = 90)\n",
    "    ax2.set_xlabel(col_name)\n",
    "    \n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4889febc",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_feature('loan_amnt', True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43c702f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1156fa2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = df.corr(method = 'spearman')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff8f486f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10, 8))\n",
    "sns.heatmap(corr.abs(), cmap ='viridis' )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ebc8340",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_corr = corr.abs()\n",
    "new_corr.loc[:,:] = np.tril(new_corr, k=-1) # below main lower triangle of an array\n",
    "new_corr = new_corr.stack().to_frame('correlation').reset_index().sort_values(by='correlation', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "609b350b",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_corr[new_corr.correlation > 0.6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "983bb61a",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_features = df.select_dtypes(include=['int32', 'int64', 'float64']).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cc1a891",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07bf9af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram with Kernel Density Estimate Plot (KDE)\n",
    "# Source: https://stackoverflow.com/questions/43638851/pandas-histogram-plot-with-kde\n",
    "def plot_histograms(df, columns):\n",
    "    # keep total number of subplot\n",
    "    k = len(df.columns)\n",
    "    # n = number of chart columns\n",
    "    n = columns\n",
    "    m = (k - 1) // n + 1\n",
    "    \n",
    "    # Create figure\n",
    "    fig, axes = plt.subplots(m, n, figsize=(n * 5, m * 3))\n",
    "\n",
    "    # Iterate through columns, tracking the column name and \n",
    "    # which number we are at i. Within each iteration, plot\n",
    "    for i, (name, col) in enumerate(df.iteritems()):\n",
    "        r, c = i // n, i % n\n",
    "        ax = axes[r, c]\n",
    "        # the histogram\n",
    "        col.hist(ax=ax)\n",
    "        # kde = Kernel Density Estimate plot\n",
    "        ax2 = col.plot.kde(ax=ax, secondary_y=True, title=name)\n",
    "        ax2.set_ylim(0)\n",
    "\n",
    "    # Use tight_layout() as an easy way to sharpen up the layout spacing\n",
    "    fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc52c0df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# selecciono algunas como ejemplo, por ejemplo, los ID no hay que incluirlos nunca en el EDA\n",
    "plot_histograms(df=df[['loan_amnt', 'funded_amnt', 'funded_amnt_inv',\n",
    "       'installment', 'annual_inc', 'dti', 'delinq_2yrs', 'fico_range_low',\n",
    "       'fico_range_high']], columns=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8033824",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(style=\"white\")\n",
    "\n",
    "# Compute the correlation matrix\n",
    "corr = df[['loan_amnt', 'funded_amnt', 'funded_amnt_inv', \n",
    "           'installment', 'annual_inc', 'dti', 'delinq_2yrs', \n",
    "           'fico_range_low','fico_range_high']].corr()\n",
    "\n",
    "# Generate a mask for the upper triangle\n",
    "mask = np.zeros_like(corr, dtype=np.bool)\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "\n",
    "# Set up the matplotlib figure\n",
    "f, ax = plt.subplots(figsize=(11, 9))\n",
    "\n",
    "# Generate a custom diverging colormap\n",
    "cmap = sns.diverging_palette(220, 10, as_cmap=True)\n",
    "\n",
    "# Draw the heatmap with the mask and correct aspect ratio\n",
    "sns.heatmap(corr, mask=mask, cmap=cmap, vmax=.3, center=0,\n",
    "            square=True, linewidths=.5, cbar_kws={\"shrink\": .5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6908c2c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "\n",
    "from sklearn.utils import resample\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_validate, KFold\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc, \\\n",
    "                            silhouette_score, recall_score, precision_score, make_scorer, \\\n",
    "                            roc_auc_score, f1_score, precision_recall_curve\n",
    "\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, \\\n",
    "                            classification_report, confusion_matrix\n",
    "\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import plot_confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0edc259",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfe965ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Combining numerical and categorical piepline into one big pipeline horizontally using ColumnTransformer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "## No podemos utilizar TransformTargetRegression porque estamos en un modelo de clasificacion\n",
    "# from 'Y' and 'N' to numeric values\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from sklearn.metrics import accuracy_score, log_loss\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC, LinearSVC, NuSVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc941233",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leería los datos que ya los tendría preparados\n",
    "df_selected = pd.read_csv('../data/raw/df_selected.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bda0c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_selected.describe(include = 'all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86bc53c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(ytest, ypred, ypred_proba = None):\n",
    "    if ypred_proba is not None:\n",
    "        print('ROC-AUC score of the model: {}'.format(roc_auc_score(ytest, ypred_proba[:, 1])))\n",
    "    print('Accuracy of the model: {}\\n'.format(accuracy_score(ytest, ypred)))\n",
    "    print('Classification report: \\n{}\\n'.format(classification_report(ytest, ypred)))\n",
    "    print('Confusion matrix: \\n{}\\n'.format(confusion_matrix(ytest, ypred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67a45a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_major = df_selected[df_selected.loan_status == 0]\n",
    "df_minor = df_selected[df_selected.loan_status == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c83a80f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_minor_upsmapled = resample(df_minor, replace = True, n_samples = 358436, random_state = 12345)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fa97f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_minor_upsmapled = pd.concat([df_minor_upsmapled, df_major])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9765368e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_minor_upsmapled.loan_status.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4200af39",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_minor_upsmapled.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f220e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining the steps in the numerical pipeline \n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())])\n",
    "\n",
    "#Defining the steps in the categorical pipeline \n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "    \n",
    "    \n",
    "#Numerical features to pass down the numerical pipeline \n",
    "numeric_features = df_minor_upsmapled.select_dtypes(include=['int64', 'float64']).drop(['loan_status'], axis=1).columns\n",
    "\n",
    "#Categrical features to pass down the categorical pipeline \n",
    "categorical_features = df_minor_upsmapled.select_dtypes(include=['object']).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0371fae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_minor_upsmapled.drop('loan_status', axis = 1)\n",
    "Y = df_minor_upsmapled.loan_status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a98de37",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = LabelEncoder().fit_transform(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6afeb7b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain, xtest, ytrain, ytest = train_test_split(X, Y, test_size=0.25, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f159af2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6463fbe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = [\n",
    "    DecisionTreeClassifier(),\n",
    "    RandomForestClassifier(),\n",
    "    AdaBoostClassifier(),\n",
    "    GradientBoostingClassifier()\n",
    "    ]\n",
    "\n",
    "for classifier in classifiers:\n",
    "    pipe = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                      ('classifier', classifier)])\n",
    "    pipe.fit(xtrain, ytrain)   \n",
    "    print(classifier)\n",
    "    print(\"model score: %.3f\" % pipe.score(xtest, ytest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b75e7c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                      ('classifier', RandomForestClassifier())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41599b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Parameter Tunning Optimization\n",
    "param_grid = { \n",
    "    'classifier__n_estimators': [200], # poner tantos como se quiera probar\n",
    "    'classifier__max_features': ['auto'], #['auto', 'sqrt', 'log2']\n",
    "    'classifier__max_depth' : [4], # [4,5,6,7,8]\n",
    "    'classifier__criterion' :['gini']} #['gini', 'entropy']\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "\n",
    "CV = RandomizedSearchCV(rf, param_grid, cv=10, random_state=12345, n_jobs=2)\n",
    "                  \n",
    "CV.fit(xtrain, ytrain)  \n",
    "print(CV.best_params_)    \n",
    "print(CV.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e756d039",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = CV.predict(xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aa789ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Classification Report\")\n",
    "print(classification_report(ytest, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df92ade1",
   "metadata": {},
   "outputs": [],
   "source": [
    "CV.best_estimator_.named_steps['classifier'].feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d917b623",
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_predictions = CV.predict_proba(xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd61736c",
   "metadata": {},
   "outputs": [],
   "source": [
    "recall_score(ytest, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95f9d14b",
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_score(ytest, predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "627edd4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_gbt = confusion_matrix(ytest, predictions)\n",
    "\n",
    "plt.figure(figsize=(9,9))\n",
    "sns.heatmap(cm_gbt, annot=True, fmt=\".3f\", linewidths=.5, square = True, cmap = 'Blues_r');\n",
    "plt.ylabel('Actual label');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76f809af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot non-normalized confusion matrix\n",
    "titles_options = [(\"Confusion matrix, without normalization\", None),\n",
    "                  (\"Normalized confusion matrix\", 'true')]\n",
    "for title, normalize in titles_options:\n",
    "    disp = plot_confusion_matrix(CV, xtest, ytest,\n",
    "                                 # display_labels=ytest,\n",
    "                                 cmap=plt.cm.Blues,\n",
    "                                 normalize=normalize)\n",
    "    disp.ax_.set_title(title)\n",
    "\n",
    "    print(title)\n",
    "    print(disp.confusion_matrix)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe32db4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep probabilities for the positive outcome only\n",
    "yhat = prob_predictions[:, 1]\n",
    "# calculate roc curves\n",
    "fpr, tpr, thresholds = roc_curve(ytest, yhat)\n",
    "# plot the roc curve for the model\n",
    "plt.plot([0,1], [0,1], linestyle='--', label='No Skill')\n",
    "plt.plot(fpr, tpr, marker='.', label='Random Forest')\n",
    "# axis labels\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.legend()\n",
    "# show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e87c9f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the g-mean for each threshold\n",
    "gmeans = np.sqrt(tpr * (1-fpr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0839f8b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# locate the index of the largest g-mean\n",
    "ix = np.argmax(gmeans)\n",
    "print('Best Threshold=%f, G-Mean=%.3f' % (thresholds[ix], gmeans[ix]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a332c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the roc curve for the model\n",
    "plt.plot([0,1], [0,1], linestyle='--', label='No Skill')\n",
    "plt.plot(fpr, tpr, marker='.', label='Random Forest')\n",
    "plt.scatter(fpr[ix], tpr[ix], s=100, marker='o', color='black', label='Best')\n",
    "# axis labels\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.legend()\n",
    "# show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3334346",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate pr-curve\n",
    "precision, recall, thresholds = precision_recall_curve(ytest, yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f582d5e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the roc curve for the model\n",
    "no_skill = len(ytest[ytest==1]) / len(ytest)\n",
    "plt.plot([0,1], [no_skill,no_skill], linestyle='--', label='No Skill')\n",
    "plt.plot(recall, precision, marker='.', label='Random Forest')\n",
    "# axis labels\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.legend()\n",
    "# show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbac3fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to f score\n",
    "fscore = (2 * precision * recall) / (precision + recall)\n",
    "# locate the index of the largest f score\n",
    "ix = np.argmax(fscore)\n",
    "print('Best Threshold=%f, F-Score=%.3f' % (thresholds[ix], fscore[ix]))\n",
    "# plot the roc curve for the model\n",
    "no_skill = len(ytest[ytest==1]) / len(ytest)\n",
    "plt.plot([0,1], [no_skill,no_skill], linestyle='--', label='No Skill')\n",
    "plt.plot(recall, precision, marker='.', label='Random Forest')\n",
    "plt.scatter(recall[ix], precision[ix], s=100, marker='o', color='black', label='Best')\n",
    "# axis labels\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.legend()\n",
    "# show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "173e6ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate the model\n",
    "score = f1_score(ytest, predictions)\n",
    "print('F-Score: %.5f' % score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3823331e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scikitplot as skplt\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "skplt.metrics.plot_cumulative_gain(ytest, prob_predictions)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39f7b55c",
   "metadata": {},
   "outputs": [],
   "source": [
    "skplt.metrics.plot_lift_curve(ytest, prob_predictions)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77f58a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/slundberg/shap\n",
    "import shap # cada notebook tendría sus respectivos import al inicio para mejor organización\n",
    "\n",
    "# load JS visualization code to notebook\n",
    "shap.initjs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ec4f0ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = shap.TreeExplainer(CV.best_estimator_.named_steps['classifier'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aba8a449",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = rf.named_steps[\"preprocessor\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d8bd051",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "def get_feature_names(column_transformer):\n",
    "    \"\"\"Get feature names from all transformers.\n",
    "    Returns\n",
    "    -------\n",
    "    feature_names : list of strings\n",
    "        Names of the features produced by transform.\n",
    "    \"\"\"\n",
    "    # Remove the internal helper function\n",
    "    #check_is_fitted(column_transformer)\n",
    "    \n",
    "    # Turn loopkup into function for better handling with pipeline later\n",
    "    def get_names(trans):\n",
    "        # >> Original get_feature_names() method\n",
    "        if trans == 'drop' or (\n",
    "                hasattr(column, '__len__') and not len(column)):\n",
    "            return []\n",
    "        if trans == 'passthrough':\n",
    "            if hasattr(column_transformer, '_df_columns'):\n",
    "                if ((not isinstance(column, slice))\n",
    "                        and all(isinstance(col, str) for col in column)):\n",
    "                    return column\n",
    "                else:\n",
    "                    return column_transformer._df_columns[column]\n",
    "            else:\n",
    "                indices = np.arange(column_transformer._n_features)\n",
    "                return ['x%d' % i for i in indices[column]]\n",
    "        if not hasattr(trans, 'get_feature_names'):\n",
    "        # >>> Change: Return input column names if no method avaiable\n",
    "            # Turn error into a warning\n",
    "            warnings.warn(\"Transformer %s (type %s) does not \"\n",
    "                                 \"provide get_feature_names. \"\n",
    "                                 \"Will return input column names if available\"\n",
    "                                 % (str(name), type(trans).__name__))\n",
    "            # For transformers without a get_features_names method, use the input\n",
    "            # names to the column transformer\n",
    "            if column is None:\n",
    "                return []\n",
    "            else:\n",
    "                return [name + \"__\" + f for f in column]\n",
    "\n",
    "        return [name + \"__\" + f for f in trans.get_feature_names()]\n",
    "    \n",
    "    ### Start of processing\n",
    "    feature_names = []\n",
    "    \n",
    "    # Allow transformers to be pipelines. Pipeline steps are named differently, so preprocessing is needed\n",
    "    if type(column_transformer) == sklearn.pipeline.Pipeline:\n",
    "        l_transformers = [(name, trans, None, None) for step, name, trans in column_transformer._iter()]\n",
    "    else:\n",
    "        # For column transformers, follow the original method\n",
    "        l_transformers = list(column_transformer._iter(fitted=True))\n",
    "    \n",
    "    \n",
    "    for name, trans, column, _ in l_transformers: \n",
    "        if type(trans) == sklearn.pipeline.Pipeline:\n",
    "            # Recursive call on pipeline\n",
    "            _names = get_feature_names(trans)\n",
    "            # if pipeline has no transformer that returns names\n",
    "            if len(_names)==0:\n",
    "                _names = [name + \"__\" + f for f in column]\n",
    "            feature_names.extend(_names)\n",
    "        else:\n",
    "            feature_names.extend(get_names(trans))\n",
    "    \n",
    "    return feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6dafc00",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_columns = get_feature_names(preprocessor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61ba5d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(all_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c4f5d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.DataFrame.sparse.from_spmatrix(rf['preprocessor'].transform(xtest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "952cfee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.columns = all_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaec88f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bc21681",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_values = explainer.shap_values(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb6311d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.iloc[0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "753cad9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(shap_values[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e96985e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize the first prediction's explanation (use matplotlib=True to avoid Javascript)\n",
    "shap.force_plot(explainer.expected_value[0], shap_values[0][0], test_data.iloc[0,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5472c648",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.force_plot(explainer.expected_value[0], shap_values[0][:100,:], features=test_data.iloc[:100, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6cb00ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize the effects of all the features\n",
    "shap.summary_plot(shap_values, test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1f47ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.summary_plot(shap_values[0], features=test_data, max_display=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8794bc89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75ca8252",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eb5e8d6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Practica0",
   "language": "python",
   "name": "practica0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
